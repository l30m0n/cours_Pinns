{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cb3a74-f520-4d8b-891f-885452024608",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks (PINNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2ced8-20d2-41c7-8f89-6f312d55eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Define the random seed for reproductibility\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Check if we run on GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Running on {device}. Have fun!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335804ff-dfa8-4773-8634-31948aa03df3",
   "metadata": {},
   "source": [
    "## Definition of the Partial Differential Equation (PDE) to solve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1e721-e212-4343-91dc-191d2b4d3235",
   "metadata": {},
   "source": [
    "We want to solve Helmoltz equation on a 2D square domain $$\\Large \\nabla^2 u + k^2 u = f$$\n",
    "\n",
    "The source term is defined as $$\\Large f = (-(a_1\\pi)^2 - (a_2\\pi)^2 + k^2) sin(a_1\\pi x) sin(a_2\\pi y) $$\n",
    "\n",
    "We use the Dirichlet boundary conditions with a value 0 at the boundaries of the domain.\n",
    "\n",
    "The solution has the form $$\\Large u = sin(a_1\\pi x) sin(a_2\\pi y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1121be7-5b99-4a7e-8396-08193568b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDE configurations\n",
    "a1 = 2\n",
    "a2 = 1\n",
    "k  = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a343a4-a24f-412c-9aed-64b577581319",
   "metadata": {},
   "source": [
    "## Definition of the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9365aa-e357-4b87-b519-2b07d0ac423e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "## Domain bounds\n",
    "x_bound_low = -1\n",
    "x_bound_up  =  1\n",
    "y_bound_low = -1\n",
    "y_bound_up  =  1\n",
    "bounds = [x_bound_low, x_bound_up, y_bound_low, y_bound_up]\n",
    "\n",
    "## Test points\n",
    "num_test_x =  120\n",
    "num_test_y =  120\n",
    "X, Y       = np.meshgrid(np.linspace(x_bound_low,x_bound_up,num_test_x), np.linspace(y_bound_low,y_bound_up,num_test_y))\n",
    "Test_exact = (np.sin(a1 * np.pi * X) * np.sin(a2 * np.pi * Y)).flatten()[:,None]  # Exact solution\n",
    "X_test     = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))                # Test points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35318b6f-c919-44b9-a39f-ae95eae78185",
   "metadata": {},
   "source": [
    "## Define a Random Uniform sampler on the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7da0d-7582-491e-b3dd-225776199c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RandomSampling(Ncollocation, Nbounds, bounds):\n",
    "    ## Collocation points, inside domain for training\n",
    "    x = np.random.uniform(bounds[0], bounds[1], Ncollocation)\n",
    "    y = np.random.uniform(bounds[2], bounds[3], Ncollocation)\n",
    "    X_f_train = np.hstack((x.flatten()[:,None], y.flatten()[:,None]))\n",
    "    \n",
    "    ## Boundaries\n",
    "    ### boundaries up and down\n",
    "    x_bc_u = np.random.uniform(bounds[0], bounds[1], Nbounds)\n",
    "    y_bc_u = np.full(Nbounds, bounds[3])\n",
    "    x_bc_d = np.random.uniform(bounds[0], bounds[1], Nbounds)\n",
    "    y_bc_d = np.full(Nbounds, bounds[2])\n",
    "    ### boundaries left and right\n",
    "    y_bc_l = np.random.uniform(bounds[2], bounds[3], Nbounds)\n",
    "    x_bc_l = np.full(Nbounds, bounds[0])\n",
    "    y_bc_r = np.random.uniform(bounds[2], bounds[3], Nbounds)\n",
    "    x_bc_r = np.full(Nbounds, bounds[1])\n",
    "\n",
    "    X_star = np.hstack((np.vstack([x_bc_u,x_bc_d,x_bc_l,x_bc_r]).flatten()[:,None], np.vstack([y_bc_u,y_bc_d,y_bc_l,y_bc_r]).flatten()[:,None]))\n",
    "    return X_f_train, X_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3d23b-7139-412d-8c3f-059bcd664c94",
   "metadata": {},
   "source": [
    "## Collocation points for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00012379-3298-41d8-b5af-52f9cba62cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train points\n",
    "Ncollocation      = 1024\n",
    "Nbounds           = 256\n",
    "X_f_train, X_star = RandomSampling(Ncollocation, Nbounds, bounds)\n",
    "Exact_bc          = np.zeros(X_star.shape[0]).flatten()[:,None]\n",
    "lb                = X_star.min(0)\n",
    "ub                = X_star.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152215a-3b9c-4aa6-a9ac-47cc5ef56f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, X_bc, U_bc, X_f, X_test, U_exact, layers, lb, ub, a1, a2, k, device):\n",
    "        super().__init__() \n",
    "        # bounds\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "\n",
    "        # data\n",
    "        ## Boundaries\n",
    "        self.X_bc = torch.tensor(X_bc, requires_grad=True).float().to(device)  # Boundary points\n",
    "        self.U_bc = torch.tensor(U_bc).float().to(device)                      # Field Value at boundary\n",
    "\n",
    "        ## Domain, collocation points'\n",
    "        self.x        = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device) \n",
    "        self.y        = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.residu_target = torch.zeros(X_f.shape[0],1).to(device)\n",
    "\n",
    "        ## Test\n",
    "        self.X_test  = torch.tensor(X_test , requires_grad=False).float().to(device) # Test points\n",
    "        self.U_exact = torch.tensor(U_exact, requires_grad=False).float().to(device) # Exact value\n",
    "\n",
    "        # PDE parameters\n",
    "        self.pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "        self.k  = k\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "\n",
    "        # NN\n",
    "        self.layers = layers\n",
    "        self.best   = np.Infinity\n",
    "              \n",
    "        ## activation function\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        ## loss function\n",
    "        self.loss_function = torch.nn.MSELoss(reduction ='mean')\n",
    "        ## Initialize neural network as a list using nn.Modulelist' \n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(self.layers[i], self.layers[i+1]) for i in range(len(self.layers)-1)])\n",
    "        \n",
    "        self.iter = 0\n",
    "        ## Xavier Normal Initialization\n",
    "        for i in range(len(self.layers)-1):\n",
    "            torch.nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            torch.nn.init.zeros_(self.linears[i].bias.data)\n",
    "            \n",
    "    ## forward pass\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        \n",
    "        u_b = self.ub[0]\n",
    "        l_b = self.lb[0]\n",
    "        x   = (x - l_b)/(u_b - l_b)\n",
    "        a   = x.float()\n",
    "\n",
    "        for i in range(len(self.layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "        a = self.linears[-1](a)\n",
    "        return a\n",
    "                        \n",
    "    def loss_BC(self,bc_points,u_bc):\n",
    "        loss_bc = self.loss_function(self.forward(bc_points), u_bc)\n",
    "        return loss_bc\n",
    " \n",
    "    def loss_PDE(self, x, y):\n",
    "        u = self.forward(torch.hstack((x, y)))\n",
    "        s = ( -(self.a1*self.pi)**2 - (self.a2*self.pi)**2 + self.k**2 ) * torch.sin(self.a1*self.pi*x) * torch.sin(self.a2*self.pi*y)\n",
    "        \n",
    "        u_x  = torch.autograd.grad(u  , x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_y  = torch.autograd.grad(u  , y, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y, y, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        \n",
    "        residu = u_xx + u_yy + self.k**2 * u - s                 \n",
    "        \n",
    "        loss_f = self.loss_function(residu,self.residu_target)\n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self):\n",
    "        loss_bc  = self.loss_BC(self.X_bc,self.U_bc)\n",
    "        loss_f   = self.loss_PDE(self.x,self.y)\n",
    "        loss_val = loss_bc + loss_f\n",
    "        return loss_val, loss_bc, loss_f\n",
    "    \n",
    "    def closure(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss, loss_bc, loss_f = self.loss()\n",
    "        loss.backward()\n",
    "        return loss, loss_bc, loss_f       \n",
    "\n",
    "    def train(self, model, nstep=100, log_every=100, LossFile='Loss.dat'):\n",
    "        start_time = time.time()\n",
    "        tin=time.time()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,)\n",
    "        with open(LossFile, 'w') as f:\n",
    "            f.write(f\"# Iter         Loss       Loss BC      Loss Dom.\\n\")\n",
    "            for it in range(nstep):\n",
    "                loss, loss_bc, loss_f = self.optimizer.step(model.closure)\n",
    "                # Test the model and log information \n",
    "                if self.iter % log_every == 0:\n",
    "                    error_vec, _ = self.test()\n",
    "                    f.write(f\"{self.iter:6d} {loss.item():12f}, {loss_bc.item():12f}, {loss_f.item():12f}\\n\")\n",
    "                    print(f\"{self.iter:6d}: Loss = {loss.item():>12.5f}; Error = {error_vec.item():<12.5f}\")\n",
    "                # Save the model if it improves\n",
    "                if loss.item() < self.best:\n",
    "                    torch.save(self.state_dict(), \"model.pt\")\n",
    "                    self.best = loss.item()\n",
    "                self.iter += 1\n",
    "        \n",
    "        tout=time.time()\n",
    "        print(\"Elapsed: \",tout-tin,\" seconds\")\n",
    "    \n",
    "    def test(self):\n",
    "        u_pred = self.forward(self.X_test)\n",
    "        error_vec = torch.linalg.norm((self.U_exact-u_pred),2)/torch.linalg.norm(self.U_exact,2)\n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "        return error_vec, u_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e3ad3-279d-4eb5-ae01-83b20e058962",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We use a MultiLayer Perceptron with 2 hidden layers with 256 neurons each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a9d25-5f1c-49b2-948d-e37ebbcada5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN configuration\n",
    "layers = [2, 256, 256, 1]\n",
    "\n",
    "# Training Time\n",
    "model = FCN(X_star, Exact_bc, X_f_train, X_test, Test_exact, layers, lb, ub, a1, a2, k, device)\n",
    "model.to(device)\n",
    "\n",
    "model.train(model, nstep=30000, log_every=500, LossFile='Loss.dat')\n",
    "\n",
    "''' Model Accuracy '''\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "error_vec, u_pred = model.test()\n",
    "error_u = np.linalg.norm(Test_exact-u_pred,2)/np.linalg.norm(Test_exact,2)\n",
    "print('Error u: %e' % (error_u))\n",
    "Error = np.abs(Test_exact - u_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227b27a-2bf7-44f6-b679-33c50c00a379",
   "metadata": {},
   "source": [
    "# Lets plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0103d-625d-44f3-9a4d-970b766b0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "outputfile=\"output.png\"    \n",
    "fig = plt.figure()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(19)\n",
    "\n",
    "# Plot the Error\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "shw1 = plt.imshow(Error.reshape((num_test_x, num_test_y)), cmap='gist_earth', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw1)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "ax1.set_title(\"Error\")\n",
    "\n",
    "# Plot the Predicted values for the NN\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "shw2 = plt.imshow(u_pred.reshape((num_test_x, num_test_y)), cmap='rainbow', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')    \n",
    "ax2.set_title(\"Predicted\")\n",
    "\n",
    "# Plot the exact solution\n",
    "plt.subplot(1, 3, 3)\n",
    "ax3 = plt.subplot(133)\n",
    "shw3 = plt.imshow(Test_exact.reshape((num_test_x, num_test_y)), cmap='rainbow', interpolation=\"none\", aspect='auto', extent=(x_bound_low, x_bound_up, y_bound_low, y_bound_up))\n",
    "plt.colorbar(shw3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')  \n",
    "ax3.set_title(\"Exact\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa408c6e-0272-4f46-b675-0c330883152e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9148f-12fb-4845-813f-908b9c391296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
